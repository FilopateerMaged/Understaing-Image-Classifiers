{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.7.8","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# General Image Classifer CS 58 \n## classifying numbers (mnist dataset)\n#### Filopateer Maged","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nprint(tf.__version__)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mnist = tf.keras.datasets.mnist\n(x_train, y_train),(x_test, y_test) = mnist.load_data() ## X_train is the features while Y_train are the Labels","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Priniting the actual data and visualizing it","metadata":{}},{"cell_type":"code","source":"print(x_train[0])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Using Matplotlib to turn the above data into a visual picture for us to see ","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.imshow(x_train[0],cmap=plt.cm.binary)\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### If we print the label data in this case Y for the same image labeled as 0 we can see that it's clearly a 5 ","metadata":{}},{"cell_type":"code","source":"print(y_train[0]) ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### in order to calculate the gradient descent properly we need to get rid of all the unecessary values and normalize the pictures for the data to be between 0 and 1 ","metadata":{}},{"cell_type":"code","source":"x_train = tf.keras.utils.normalize(x_train, axis=1)\nx_test = tf.keras.utils.normalize(x_test, axis=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### We can see how that affects the image and keeps the features we need while doing so by printing the same photo again","metadata":{}},{"cell_type":"code","source":"plt.imshow(x_train[0],cmap=plt.cm.binary)\nplt.show()\n#we can also look at the changes to the pixel value array by printing it using (print x_train[0])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Building the Neural Model\n#### in this case our dataset consists of 2D pictures so we can build a feed forward model for quicker computing and minimizing the loss\n## The model will consist of an input layer, 2 hidden ones and the output layer","metadata":{}},{"cell_type":"code","source":"model = tf.keras.models.Sequential()\nmodel.add(tf.keras.layers.Flatten()) # turning the multidimensional 2D array/image 28 * 28 into a 1 * 784\nmodel.add(tf.keras.layers.Dense(128, activation=tf.nn.relu)) #hidden layer with rectified linear activation\nmodel.add(tf.keras.layers.Dense(128, activation=tf.nn.relu)) #second hidden layer \nmodel.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax)) #output layer notice we only have 10 neurons represting the number of our data\nmodel.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\nmodel.fit(x_train, y_train, epochs=7)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.keras.models.save_model('lol.h5')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### As we can see the neural model learned to generalize and has an accuracy of 98%\n### but maybe it memorized all the data it was shown instead ?\n### to determine the actual loss and accuracy we're gonna use data that wasn't in the training data set ","metadata":{}},{"cell_type":"code","source":"val_loss, val_acc = model.evaluate(x_test, y_test)\nprint(val_loss)\nprint(val_acc)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### We can see in the cell above how the real accuracy fell down a percent and the loss got bigger ","metadata":{}},{"cell_type":"code","source":"predictions = model.predict(x_test)\nprint(predictions)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# So how can we as humans tell by looking at all this if it's doing a good job classyfing all those numbers ?\n### we can simply print a prediction and then visualize the same image and see if they match or not ","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\nprint(np.argmax(predictions[2]))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### The above prediction says that the image with the iteration 2 is a 1 so let's print that picture and see if it actually is a 1 ","metadata":{}},{"cell_type":"code","source":"plt.imshow(x_test[2],cmap=plt.cm.binary)\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}